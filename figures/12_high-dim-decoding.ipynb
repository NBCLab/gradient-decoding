{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "\n",
    "from surfplot.utils import add_fslr_medial_wall\n",
    "from neuromaps.datasets import fetch_fslr\n",
    "from sklearn.cluster import KMeans\n",
    "from surfplot import Plot\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from gradec.decode import LDADecoder\n",
    "from gradec.utils import _rm_medial_wall, _decoding_filter\n",
    "from gradec.plot import plot_radar, plot_cloud\n",
    "from gradec.fetcher import _fetch_features, _fetch_frequencies, _fetch_classification\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE, DENSITY = \"fsLR\", \"32k\"\n",
    "DSET, MODEL = \"neuroquery\", \"lda\"\n",
    "\n",
    "data_dir = op.join(\".\", \"temp_fig\")\n",
    "neuromaps_dir = op.join(data_dir, \"neuromaps\")\n",
    "figures_dir = op.join(data_dir, \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = LDADecoder(space=SPACE, density=DENSITY, calc_pvals=False, data_dir=data_dir)\n",
    "decode.fit(DSET)\n",
    "\n",
    "# Load features for visualization\n",
    "features = _fetch_features(DSET, MODEL, data_dir=data_dir)\n",
    "frequencies = _fetch_frequencies(DSET, MODEL, data_dir=data_dir)\n",
    "classification, class_lst = _fetch_classification(DSET, MODEL, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = np.load(\"../results/gradient/gradients.npy\")\n",
    "\n",
    "template_dir = \"../data/templates\"\n",
    "subcortical_fn = op.join(template_dir, \"rois-subcortical_mni152_mask.nii.gz\")\n",
    "subcort_img = nib.load(subcortical_fn)\n",
    "\n",
    "full_vertices = 64984\n",
    "hemi_vertices = full_vertices // 2\n",
    "\n",
    "subcort_dat = subcort_img.get_fdata()\n",
    "subcort_mask = subcort_dat != 0\n",
    "n_subcort_vox = np.where(subcort_mask)[0].shape[0]\n",
    "\n",
    "n_gradients = gradients.shape[1]\n",
    "grad_lst = []\n",
    "for i in range(n_gradients):\n",
    "    cort_grads = gradients[: gradients.shape[0] - n_subcort_vox, i]\n",
    "    grad_lst.append(cort_grads)\n",
    "\n",
    "grad_arr = np.array(grad_lst).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dir = \"../results/segmentation/KMeans_gradient-maps\"\n",
    "n_clusters = 2\n",
    "n_dim = 1\n",
    "sigma_0 = 0.1\n",
    "\n",
    "surfaces = fetch_fslr()\n",
    "lh, rh = surfaces['inflated']\n",
    "sulc_lh, sulc_rh = surfaces['sulc']\n",
    "\n",
    "full_vertices = 64984\n",
    "hemi_vertices = full_vertices // 2\n",
    "\n",
    "cmap = \"YlOrRd\"\n",
    "act_maps = []\n",
    "for region in range(n_clusters):\n",
    "    map_lh = op.join(seg_dir, f\"source-KMeans{n_clusters:02d}_desc-C{region:02d}_space-fsLR_den-32k_hemi-L_feature.func.gii\")\n",
    "    map_rh = op.join(seg_dir, f\"source-KMeans{n_clusters:02d}_desc-C{region:02d}_space-fsLR_den-32k_hemi-R_feature.func.gii\")\n",
    "    map_arr_lh = nib.load(map_lh).agg_data()\n",
    "    map_arr_rh = nib.load(map_rh).agg_data()\n",
    "    pseudo_act_map = _rm_medial_wall(\n",
    "        map_arr_lh,\n",
    "        map_arr_rh,\n",
    "        space=SPACE,\n",
    "        density=DENSITY,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    "    )\n",
    "\n",
    "    # Decode map\n",
    "    corrs_df = decode.transform([pseudo_act_map], method=\"correlation\")\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "    filtered_df.columns = [\"r\"]\n",
    "\n",
    "    # Visualize results\n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "    # Radar plot\n",
    "    plot_radar(\n",
    "        corrs, \n",
    "        filtered_features,\n",
    "        MODEL,\n",
    "        cmap=cmap,\n",
    "        out_fig=op.join(data_dir, f\"od_{region:02d}_radar.png\"),\n",
    "    )\n",
    "\n",
    "    # Word cloud plot\n",
    "    plot_cloud(\n",
    "        corrs, \n",
    "        filtered_features,\n",
    "        filtered_frequencies,\n",
    "        MODEL, \n",
    "        cmap=cmap,\n",
    "        data_dir=data_dir,\n",
    "        out_fig=op.join(data_dir, f\"od_{region:02d}_wordcloud.png\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "cmap = \"YlOrRd\"\n",
    "grad_ = grad_arr[:, dim]\n",
    "n_segment = 2\n",
    "kmeans_model = KMeans(\n",
    "    n_clusters=n_segment,\n",
    "    init=\"k-means++\",\n",
    "    n_init=10,\n",
    "    random_state=0,\n",
    "    algorithm=\"elkan\",\n",
    ").fit(grad_.reshape(-1, 1))\n",
    "# Get order mapper from map_peaks\n",
    "peaks = kmeans_model.cluster_centers_\n",
    "map_peaks = peaks[:, 0].flatten()  # Order base on principal gradient\n",
    "order_idx = np.argsort(map_peaks)\n",
    "order_mapper = np.zeros_like(order_idx)\n",
    "order_mapper[order_idx] = np.arange(n_segment)\n",
    "\n",
    "max_peak, min_peak = grad_.max(), grad_.min()\n",
    "peaks[0], peaks[-1] = min_peak, max_peak\n",
    "\n",
    "# Reorder labels based on map_peaks order\n",
    "labels = order_mapper[kmeans_model.labels_]\n",
    "\n",
    "n_clusters = 2\n",
    "n_dim = 1\n",
    "sigma_0 = 1\n",
    "\n",
    "surfaces = fetch_fslr()\n",
    "lh, rh = surfaces['inflated']\n",
    "sulc_lh, sulc_rh = surfaces['sulc']\n",
    "\n",
    "full_vertices = 64984\n",
    "hemi_vertices = full_vertices // 2\n",
    "\n",
    "act_maps = []\n",
    "for region in range(n_clusters):\n",
    "    # zero-out all regions except 71 and 72\n",
    "    indices = np.where(labels==region)[0]\n",
    "    grad_val = grad_[indices]\n",
    "    peak_coords = peaks[region]\n",
    "    distances = pairwise_distances(\n",
    "        grad_val.reshape(-1, 1), \n",
    "        peak_coords.reshape(1, -1), \n",
    "        metric=\"euclidean\"\n",
    "    ).flatten()\n",
    "    mean_dist = np.mean(distances)\n",
    "    sigma = mean_dist * sigma_0\n",
    "    affinity =  np.exp(-distances**2 / (2 * sigma**2))\n",
    "\n",
    "    pseudo_act_map = np.zeros_like(labels, dtype=float)\n",
    "    \n",
    "    pseudo_act_map[indices] = np.array(affinity)\n",
    "    act_maps.append(pseudo_act_map)\n",
    "\n",
    "    prin_grad = add_fslr_medial_wall(pseudo_act_map)  # Add medial wall for plotting\n",
    "    data_lh, data_rh = prin_grad[:hemi_vertices], prin_grad[hemi_vertices:full_vertices]\n",
    "\n",
    "    # Decode map\n",
    "    corrs_df = decode.transform([pseudo_act_map], method=\"correlation\")\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "    filtered_df.columns = [\"r\"]\n",
    "\n",
    "    # Visualize results\n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "    # Radar plot\n",
    "    plot_radar(\n",
    "        corrs, \n",
    "        filtered_features,\n",
    "        MODEL,\n",
    "        cmap=cmap,\n",
    "        out_fig=op.join(data_dir, f\"{dim}-{region:02d}_radar.png\"),\n",
    "    )\n",
    "\n",
    "    # Word cloud plot\n",
    "    plot_cloud(\n",
    "        corrs, \n",
    "        filtered_features,\n",
    "        filtered_frequencies,\n",
    "        MODEL, \n",
    "        cmap=cmap,\n",
    "        data_dir=data_dir,\n",
    "        out_fig=op.join(data_dir, f\"{dim}-{region:02d}_wordcloud.png\"),\n",
    "    )\n",
    "\n",
    "\n",
    "    p = Plot(lh, rh)\n",
    "    p.add_layer({'left': sulc_lh, 'right': sulc_rh}, cmap='binary_r', cbar=False)\n",
    "    p.add_layer({'left': data_lh, 'right': data_rh}, color_range=(0, 1), cmap=\"YlOrRd\")\n",
    "    fig = p.build()\n",
    "    fig.savefig(op.join(data_dir, f\"{dim}-{region:02d}_map.tiff\"), bbox_inches=\"tight\", dpi=500)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
