{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example for plotting gradient data\"\"\"\n",
    "import os.path as op\n",
    "from glob import glob\n",
    "import itertools\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from neuromaps.datasets import fetch_fslr\n",
    "from surfplot import Plot\n",
    "from gradec.fetcher import _fetch_metamaps\n",
    "from surfplot.utils import add_fslr_medial_wall, threshold\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.plotting.cm import _cmap_d as nilearn_cmaps\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surf_maps(lh_grad, rh_grad, threshold_, color_range, cmap, dpi, data_dir, out_filename):\n",
    "    neuromaps_dir = op.join(data_dir, \"neuromaps\")\n",
    "\n",
    "    surfaces = fetch_fslr(density=\"32k\", data_dir=neuromaps_dir)\n",
    "    lh, rh = surfaces[\"inflated\"]\n",
    "    sulc_lh, sulc_rh = surfaces[\"sulc\"]\n",
    "\n",
    "    lh_grad = threshold(lh_grad, threshold_)\n",
    "    rh_grad = threshold(rh_grad, threshold_)\n",
    "\n",
    "    p = Plot(lh, views=\"lateral\")\n",
    "    p.add_layer({\"left\": sulc_lh}, cmap=\"binary_r\", cbar=False)\n",
    "    p.add_layer({\"left\": lh_grad}, cmap=cmap, cbar=False, color_range=color_range,)\n",
    "    fig = p.build()\n",
    "\n",
    "    fig.savefig(out_filename, bbox_inches=\"tight\", dpi=dpi, transparent=True)\n",
    "    fig = None\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"Percentile\", \"KMeans\", \"KDE\"]\n",
    "dset_names = [\"neurosynth\", \"neuroquery\"]\n",
    "models = [\"term\", \"lda\", \"gclda\"]\n",
    "\n",
    "full_vertices = 64984\n",
    "hemi_vertices = full_vertices // 2\n",
    "\n",
    "total_methods = 18\n",
    "color_map = plt.get_cmap(\"tab20\")\n",
    "segmentations = [3, 17, 32]\n",
    "seg_sols = [[1, 2, 3], [1, 9, 17], [1, 16, 32]]\n",
    "data_df = pd.read_csv(\"../results/performance/performance.tsv\", delimiter=\"\\t\")\n",
    "map_out_path = \"../figures/Fig/decoding\"\n",
    "features_lst = []\n",
    "prefix_lst = []\n",
    "for seg_i, segmentation in enumerate(segmentations):\n",
    "    print(f\"Segmentation: {segmentation}\")\n",
    "    for seg_sol in seg_sols[seg_i]:\n",
    "        print(f\"\\tSegmentation solution: {seg_sol}\")\n",
    "        sub_features_lst = []\n",
    "        for dset_i, dset_name in enumerate(dset_names):\n",
    "            sub_class_lst = []\n",
    "            sub_features_dset_lst = []\n",
    "            for model_i, model in enumerate(models):\n",
    "                for iter_i, method in enumerate(methods):\n",
    "                \n",
    "                    method_name = f\"{model}_{dset_name}_{method}\"\n",
    "                    temp_df = data_df[\n",
    "                        (data_df[\"method\"] == method_name) & \n",
    "                        (data_df[\"segment_solution\"] == segmentation) &\n",
    "                        (data_df[\"segment\"] == seg_sol)\n",
    "                    ]\n",
    "                    corr_idx = temp_df[\"corr_idx\"].values[0]\n",
    "                    corr_idx_str = f\"{corr_idx:04d}\" if model == \"term\" else f\"{corr_idx:03d}\"\n",
    "                    \"\"\"\n",
    "                    # Get gradient maps\n",
    "                    maps_fslr = _fetch_metamaps(dset_name, model, data_dir=data_dir)\n",
    "                    data = maps_fslr[corr_idx, :]\n",
    "                    threshold_ = np.percentile(data, 80) if model == \"gclda\" else 2\n",
    "                    cmap = \"afmhot\" if model == \"gclda\" else nilearn_cmaps[\"cold_hot\"]\n",
    "                    max_val = round(np.max(np.abs(data)), 2)\n",
    "                    range_ = (0, max_val) if model == \"gclda\" else (-max_val, max_val)\n",
    "                    data = add_fslr_medial_wall(data)\n",
    "                    data_lh, data_rh = data[:hemi_vertices], data[hemi_vertices:full_vertices]\n",
    "                    \n",
    "                    prefix = f\"{segmentation:02d}-{seg_sol:02d}-{model_i}-{dset_i}-{iter_i}\"\n",
    "                    out_filename = op.join(map_out_path, f\"maps_{prefix}_{dset_name}-{model}-{method}.tiff\")\n",
    "                    plot_surf_maps(data_lh, data_rh, threshold_, range_, cmap, 100, data_dir, out_filename)\n",
    "                    \"\"\"\n",
    "                    feature = temp_df[\"features\"].values[0]\n",
    "\n",
    "                    if model != \"term\":\n",
    "                        feature = \"; \".join(feature.split(\"_\")[1:])\n",
    "\n",
    "                    sub_features_dset_lst.append(feature)\n",
    "                    sub_class_lst.append(temp_df[\"classification\"].values[0])\n",
    "            \n",
    "            sub_features_lst.append(sub_features_dset_lst)\n",
    "            \n",
    "            print(sub_class_lst)\n",
    "\n",
    "            # Plot classification\n",
    "            fig, ax = plt.subplots(1, 1)\n",
    "            fig.set_size_inches(4, 4)\n",
    "\n",
    "            n_methods = len(sub_class_lst)\n",
    "            y_coords = np.linspace(1, 0, n_methods)\n",
    "            colors = color_map.colors[:total_methods][::2] if dset_name == \"neurosynth\" else color_map.colors[:total_methods][1::2]\n",
    "\n",
    "            for y_coord, color, text in zip(y_coords, colors, sub_class_lst):\n",
    "                text_kwargs = dict(ha=\"center\", va=\"center\", weight='bold', fontsize=22, color=color)\n",
    "                text = ax.text(0.5, y_coord, text, **text_kwargs)\n",
    "\n",
    "            ax.axis('off')\n",
    "            fig.tight_layout()\n",
    "            plt.savefig(op.join(\"./Fig\", \"performance\", f\"classification-{dset_name}-{segmentation:02d}-{seg_sol:02d}.eps\"), bbox_inches=\"tight\", transparent=True)\n",
    "            plt.close()\n",
    "            gc.collect()\n",
    "            plt.clf()\n",
    "\n",
    "        sub_features_lst = [item for pair in zip(sub_features_lst[0], sub_features_lst[1]) for item in pair]\n",
    "        print(sub_features_lst)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        fig.set_size_inches(7, 8)\n",
    "\n",
    "        n_methods = len(sub_features_lst)\n",
    "        y_coords = np.linspace(1, 0, n_methods)\n",
    "\n",
    "        colors = color_map.colors[:total_methods]\n",
    "\n",
    "        for y_coord, color, text in zip(y_coords, colors, sub_features_lst):\n",
    "            text_kwargs = dict(ha=\"center\", va=\"center\", weight='bold', fontsize=22, color=color)\n",
    "            text = ax.text(0.5, y_coord, text, **text_kwargs)\n",
    "\n",
    "        ax.axis('off')\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(op.join(\"./Fig\", \"performance\", f\"features-{segmentation:02d}-{seg_sol:02d}.eps\"), bbox_inches=\"tight\", transparent=True)\n",
    "        plt.close()\n",
    "        gc.collect()\n",
    "        plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotegories = np.array([\"Functional\", \"Clinical\", \"Anatomical\", \"Non-Specific\"])\n",
    "\n",
    "methods = [\"Percentile\", \"KMeans\", \"KDE\"]\n",
    "dset_names = [\"neurosynth\", \"neuroquery\"]\n",
    "models = [\"term\", \"lda\", \"gclda\"]\n",
    "\n",
    "total_methods = 18\n",
    "color_map = plt.get_cmap(\"tab20\")\n",
    "data_df = pd.read_csv(\"../results/performance/performance.tsv\", delimiter=\"\\t\")\n",
    "features_lst = []\n",
    "prefix_lst = []\n",
    "for seg_sol in range(3,33):\n",
    "    sub_class_lst = []\n",
    "    seg_sol_lst = []\n",
    "    data2plot_df = pd.DataFrame()\n",
    "    for seg_id in range(1, seg_sol+1):\n",
    "        for dset_name, model, method in itertools.product(dset_names, models, methods):\n",
    "            method_name = f\"{model}_{dset_name}_{method}\"\n",
    "            temp_df = data_df[\n",
    "                (data_df[\"method\"] == method_name) & \n",
    "                (data_df[\"segment_solution\"] == seg_sol) &\n",
    "                (data_df[\"segment\"] == seg_id)\n",
    "            ]\n",
    "            corr_idx = temp_df[\"corr_idx\"].values[0]\n",
    "            corr_idx_str = f\"{corr_idx:04d}\" if model == \"term\" else f\"{corr_idx:03d}\"\n",
    "\n",
    "\n",
    "            sub_class_lst.append(temp_df[\"classification\"].values[0])\n",
    "            seg_sol_lst.append(seg_id)\n",
    "    \n",
    "    data2plot_df[\"segment\"] = seg_sol_lst\n",
    "    data2plot_df[\"classification\"] = sub_class_lst\n",
    "\n",
    "    cross_data_prop_df = pd.crosstab(index=data2plot_df[\"segment\"],\n",
    "                             columns=data2plot_df[\"classification\"],\n",
    "                             normalize=\"index\")\n",
    "    for category in cotegories:\n",
    "        if category not in cross_data_prop_df.columns:\n",
    "            cross_data_prop_df[category] = [0]*len(cross_data_prop_df)\n",
    "\n",
    "    cross_data_prop_df = cross_data_prop_df[cotegories]\n",
    "    cross_data_prop_df = cross_data_prop_df.sort_index(ascending=True)\n",
    "\n",
    "    fontsize = 11\n",
    "\n",
    "    colors = [\"#393E46\", '#6D9886', '#F2E7D5', '#F7F7F7']\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(9 + seg_id*0.2, 4)\n",
    "\n",
    "    cross_data_prop_df.plot(\n",
    "        kind='bar', \n",
    "        stacked=True, \n",
    "        color=colors,\n",
    "        edgecolor='white', \n",
    "        linewidth=2,\n",
    "        width=0.9,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    ax.legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1, 1),\n",
    "        ncol=1,\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    ax.set_xlabel(\"Segment ID\", fontsize=fontsize+2)\n",
    "    ax.set_ylabel(\"Proportion\", fontsize=fontsize+2)\n",
    "    ax.set_title(f\"Segment Solution: {seg_sol:02d}\", fontsize=fontsize+2)\n",
    "\n",
    "    plt.savefig(op.join(\"./Fig\", \"classification\", f\"class_segsol-{seg_sol}.eps\"), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 33):\n",
    "    print(f\"\\includegraphics[scale=0.47]{{class_segsol-{i}.eps}}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32eae8b81dca7564140c4bb02978cc1f5cb3ca50d75c604cb4f67ffb4db99fb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
